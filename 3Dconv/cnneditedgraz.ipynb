{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41385,"status":"ok","timestamp":1687037556653,"user":{"displayName":"Yige","userId":"17965974016152786492"},"user_tz":-60},"id":"SfKedXLyN9ue","outputId":"b9c9ab42-55b5-47e8-a081-1d96bdfdc196"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24144,"status":"ok","timestamp":1687037984180,"user":{"displayName":"Yige","userId":"17965974016152786492"},"user_tz":-60},"id":"8pZxbfbuRUya","outputId":"69200ba4-9393-4a3b-de29-80a56fcb6a85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Folder decompressed successfully.\n"]}],"source":["import zipfile\n","\n","# Specify the path to the zip archive\n","zip_path = '/content/drive/MyDrive/3dGrazNormalized.zip'\n","\n","# Specify the directory where you want to extract the files\n","extract_dir = '/content/'\n","\n","# Open the zip archive\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    # Extract all the contents of the zip archive to the specified directory\n","    zip_ref.extractall(extract_dir)\n","\n","print(\"Folder decompressed successfully.\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6945,"status":"ok","timestamp":1687037603958,"user":{"displayName":"Yige","userId":"17965974016152786492"},"user_tz":-60},"id":"kyBBYgDyOXl9","outputId":"2ed31ab3-d22a-4291-cbaf-1a3d43043c35"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting braindecode\n","  Downloading Braindecode-0.7-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mne (from braindecode)\n","  Downloading mne-1.4.2-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.22.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from braindecode) (3.7.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from braindecode) (3.8.0)\n","Collecting skorch (from braindecode)\n","  Downloading skorch-0.13.0-py3-none-any.whl (209 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ebraindecode) (1.0.7)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ebraindecode) (0.11.0)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ebraindecode) (4.39.3)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ebraindecode) (1.4.4)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ebraindecode) (23.1)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ebraindecode) (8.4.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ebraindecode) (3.0.9)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ebraindecode) (2.8.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne-\u003ebraindecode) (4.65.0)\n","Requirement already satisfied: pooch\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from mne-\u003ebraindecode) (1.6.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne-\u003ebraindecode) (4.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne-\u003ebraindecode) (3.1.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003ebraindecode) (2022.7.1)\n","Requirement already satisfied: scikit-learn\u003e=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch-\u003ebraindecode) (1.2.2)\n","Requirement already satisfied: tabulate\u003e=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch-\u003ebraindecode) (0.8.10)\n","Requirement already satisfied: appdirs\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch\u003e=1.5-\u003emne-\u003ebraindecode) (1.4.4)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch\u003e=1.5-\u003emne-\u003ebraindecode) (2.27.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib-\u003ebraindecode) (1.16.0)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.22.0-\u003eskorch-\u003ebraindecode) (1.2.0)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.22.0-\u003eskorch-\u003ebraindecode) (3.1.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003emne-\u003ebraindecode) (2.1.2)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003epooch\u003e=1.5-\u003emne-\u003ebraindecode) (1.26.15)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003epooch\u003e=1.5-\u003emne-\u003ebraindecode) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003epooch\u003e=1.5-\u003emne-\u003ebraindecode) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003epooch\u003e=1.5-\u003emne-\u003ebraindecode) (3.4)\n","Installing collected packages: skorch, mne, braindecode\n","Successfully installed braindecode-0.7 mne-1.4.2 skorch-0.13.0\n"]}],"source":["!pip install braindecode"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":837,"status":"ok","timestamp":1687038606626,"user":{"displayName":"Yige","userId":"17965974016152786492"},"user_tz":-60},"id":"Dq4dSfzVVKAx","outputId":"399030f5-e1e9-47dc-9f22-46ea5d6209aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape after Conv3d: torch.Size([40, 40, 6, 7, 976])\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","# Create the Conv3d layer\n","conv = nn.Conv3d(1, 40, (1, 1, 25), stride=(1, 1, 1), padding=(0, 0, 0))\n","\n","# Create a sample input tensor\n","input_tensor = torch.randn(40, 1, 6, 7, 1000)  # Adjust the input shape as needed\n","\n","# Pass the input tensor through the Conv3d layer\n","output_tensor = conv(input_tensor)\n","print(\"Output shape after Conv3d:\", output_tensor.shape)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1640,"status":"ok","timestamp":1687038681972,"user":{"displayName":"Yige","userId":"17965974016152786492"},"user_tz":-60},"id":"lLFdwGD1VkDd","outputId":"44ad7e61-0516-4887-f418-947e386532d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape after Conv3d: torch.Size([40, 40, 1, 1, 976])\n"]}],"source":["conv = nn.Conv3d(40, 40, (6, 7, 1), stride=(1,1,1), padding=(0,0,0))\n","\n","# Create a sample input tensor\n","input_tensor = torch.randn(40, 40, 6, 7, 976)  # Adjust the input shape as needed\n","\n","# Pass the input tensor through the Conv3d layer\n","output_tensor = conv(input_tensor)\n","print(\"Output shape after Conv3d:\", output_tensor.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Mz9wit9JMzn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NiK-cnHpOgoX"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","Train Loss: 1.6867 | Train Accuracy: 0.3153\n","Validation Loss: 1.6653 | Validation Accuracy: 0.2768\n","Epoch 2/100\n","Train Loss: 1.6376 | Train Accuracy: 0.3477\n","Validation Loss: 1.6213 | Validation Accuracy: 0.3125\n","Epoch 3/100\n","Train Loss: 1.4199 | Train Accuracy: 0.4557\n","Validation Loss: 1.7100 | Validation Accuracy: 0.3661\n","Epoch 4/100\n","Train Loss: 1.2820 | Train Accuracy: 0.4579\n","Validation Loss: 2.0163 | Validation Accuracy: 0.3304\n"]}],"source":["import scipy.io\n","import numpy as np\n","from skorch.helper import predefined_split\n","from sklearn.model_selection import train_test_split\n","from braindecode.models import Deep4Net\n","from braindecode import EEGClassifier\n","import torch\n","import os\n","import scipy.io\n","from skorch.callbacks import LRScheduler\n","from braindecode import EEGClassifier\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","data_dir = '/content/3dGrazNormalized/'\n","\n","\n","class ModifiedDeep4Net(nn.Module):\n","    def __init__(self):\n","        super(ModifiedDeep4Net, self).__init__()\n","        self.shallownet1 = nn.Sequential(\n","            nn.Conv3d(1, 40, (1, 1, 50), stride=(1,1,1), padding=(0,0,0)),\n","            nn.Conv3d(40, 40, (6, 7, 1), stride=(1,1,1), padding=(0,0,0)),\n","        )\n","        self.shallownet2 = nn.Sequential(\n","            nn.BatchNorm2d(40),\n","        )\n","        self.deep4net = Deep4Net(\n","            in_chans=40,  # Number of input channels\n","            n_classes=4,  # Number of classes\n","            input_window_samples=951,\n","            final_conv_length='auto'\n","        )\n","\n","    def forward(self, x):\n","        x = self.shallownet1(x)\n","        x = torch.squeeze(x, dim=2)\n","        x = self.shallownet2(x)\n","        x = x.permute(0, 1, 3, 2)\n","        x = self.deep4net(x)\n","        return x\n","\n","# Create an instance of the modified model\n","model = ModifiedDeep4Net()\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","num_epochs = 100\n","batch_size = 32\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","\n","best_valid_accuracy = []\n","aver_valid_accuracy = []\n","for i in range(1,10):\n","    log_write = open(\"log_subject%d.txt\" % i, \"w\")\n","\n","    file_name1 = f'3Dnorm_2d_{i:02d}T_P.mat'  # Construct the file name\n","    file_name2 = f'3Dnorm_2d_{i:02d}E_P.mat'  # Construct the file name\n","\n","\n","    file_path1 = os.path.join(data_dir, file_name1)  # Construct the file path\n","    file_path2 = os.path.join(data_dir, file_name2)  # Construct the file path\n","    training = scipy.io.loadmat(file_path1)\n","    testing = scipy.io.loadmat(file_path2)\n","\n","    # Assuming you have your training and testing datasets\n","    train_X, train_y = training['data'], (np.squeeze(training['label'])).astype(int)-1\n","    valid_X, valid_y = testing['data'], (np.squeeze(testing['label'])).astype(int)-1\n","\n","    # Create the dataset objects\n","    train_dataset = torch.utils.data.TensorDataset(torch.Tensor(train_X), torch.Tensor(train_y))\n","    valid_dataset = torch.utils.data.TensorDataset(torch.Tensor(valid_X), torch.Tensor(valid_y))\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","    best_valid_acc = 0\n","    aver_valid_acc = 0\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        train_acc = 0.0\n","\n","        for inputs, labels in train_loader:\n","            inputs = torch.unsqueeze(inputs, dim=1).to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.long())\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs,1)\n","            train_acc += torch.sum(preds == labels.data)\n","\n","        epoch_loss = train_loss / len(train_dataset)\n","        epoch_acc = train_acc.double() / len(train_dataset)\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print(f\"Train Loss: {epoch_loss:.4f} | Train Accuracy: {epoch_acc:.4f}\")\n","\n","        model.eval()\n","        valid_loss = 0.0\n","        valid_acc = 0.0\n","\n","        with torch.no_grad():\n","            for inputs, labels in valid_dataset:\n","                inputs = inputs.unsqueeze(0).unsqueeze(0).to(device)\n","                labels = labels.unsqueeze(0).to(device)\n","\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels.long())\n","\n","                valid_loss += loss.item() * inputs.size(0)\n","                _,preds = torch.max(outputs, 1)\n","                valid_acc += torch.sum(preds == labels.data)\n","\n","        valid_loss = valid_loss / len(valid_dataset)\n","        valid_acc = valid_acc.double() / len(valid_dataset)\n","\n","        print(f\"Validation Loss: {valid_loss:.4f} | Validation Accuracy: {valid_acc:.4f}\")\n","\n","        if best_valid_acc \u003c valid_acc:\n","            best_valid_acc = valid_acc\n","        aver_valid_acc += valid_acc\n","\n","        log_write.write(str(epoch) + \"    \" +f\"Train Loss: {epoch_loss:.4f} | Train Accuracy: {epoch_acc:.4f}  |  Validation Loss: {valid_loss:.4f} | Validation Accuracy: {valid_acc:.4f}\"+ \"\\n\")\n","\n","    best_valid_accuracy.append(best_valid_acc)\n","    aver_valid_accuracy.append(aver_valid_acc/num_epochs)\n","\n","    log_write.write('The average accuracy is: ' + str(aver_valid_acc/num_epochs) + \"\\n\")\n","    log_write.write('The best accuracy is: ' + str(best_valid_acc) + \"\\n\")\n","\n","result_write = open(\"sub_result.txt\", \"w\")\n","for i in range(len(best_valid_accuracy)):\n","    result_write.write('Subject ' + str(i + 1) + ' : ' + 'The best accuracy is: ' + str(best_valid_accuracy[i]) + \"\\n\")\n","    result_write.write('Subject ' + str(i + 1) + ' : ' + 'The average accuracy is: ' + str(aver_valid_accuracy[i]) + \"\\n\")\n","\n","best = sum(best_valid_accuracy) /9\n","aver = sum(aver_valid_accuracy) /9\n","result_write.write('**The average Best accuracy is: ' + str(best) + \"\\n\")\n","result_write.write('The average Aver accuracy is: ' + str(aver) + \"\\n\")\n","result_write.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DBzgLbRNNDwb"},"outputs":[],"source":["import shutil\n","\n","# Specify the source directory where the text files are located\n","source_directory = '/content/'\n","\n","# Specify the destination directory in your Google Drive\n","destination_directory = '/content/drive/MyDrive/result3dconv-cnngraz'\n","\n","# Move all text files from the source directory to the destination directory\n","for file_name in os.listdir(source_directory):\n","    if file_name.endswith('.txt'):\n","        file_path = os.path.join(source_directory, file_name)\n","        shutil.move(file_path, destination_directory)\n","\n","print(\"Text files moved to Google Drive successfully.\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOpanzzxXo4aa4Mft6apIEr","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}