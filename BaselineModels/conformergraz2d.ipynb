{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kY8sytOv1iOr","outputId":"6b3670d6-9b5d-4c76-f7cc-64846002dd26","executionInfo":{"status":"ok","timestamp":1686476920263,"user_tz":-60,"elapsed":5555,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting einops\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.6.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrLTZ4QQdtj0","outputId":"f65c18c1-5931-4a20-8b03-4260202ad6e1","executionInfo":{"status":"ok","timestamp":1686476979849,"user_tz":-60,"elapsed":21437,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","# Specify the source file path in your Google Drive\n","source_file_path = '/content/drive/MyDrive/2DMergedGraz/merged_Graz_2d_E.mat'\n","\n","# Specify the destination folder path in Colab\n","destination_folder_path = '/content/'\n","\n","# Copy the file from Google Drive to Colab\n","shutil.copy(source_file_path, destination_folder_path)\n","\n","source_file_path = '/content/drive/MyDrive/2DMergedGraz/merged_Graz_2d_T.mat'\n","\n","# Specify the destination folder path in Colab\n","destination_folder_path = '/content/'\n","\n","# Copy the file from Google Drive to Colab\n","shutil.copy(source_file_path, destination_folder_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"0cfG9yOpdxbs","outputId":"3418dace-794c-47f3-e888-a4ddf42a7935","executionInfo":{"status":"error","timestamp":1686477117775,"user_tz":-60,"elapsed":1626,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-339ee1671b9e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Copy the file from Google Drive to Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msource_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/2DMergedGraz/merged_Graz_2d_T.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0m_USE_CP_SENDFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                             \u001b[0m_fastcopy_sendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0m_GiveupOnFastCopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36m_fastcopy_sendfile\u001b[0;34m(fsrc, fdst)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# ...in oder to have a more informative exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import zipfile\n","\n","# Specify the path to the zip archive\n","zip_path = '/content/drive/MyDrive/2DGraz_2a.zip'\n","\n","# Specify the directory where you want to extract the files\n","extract_dir = '/content/'\n","\n","# Open the zip archive\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    # Extract all the contents of the zip archive to the specified directory\n","    zip_ref.extractall(extract_dir)\n","\n","print(\"Folder decompressed successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SpvunR2Abvxs","executionInfo":{"status":"ok","timestamp":1686001871137,"user_tz":-60,"elapsed":23847,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}},"outputId":"3b7f9826-4e01-4d82-aedb-274422781462"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Folder decompressed successfully.\n"]}]},{"cell_type":"code","source":["import scipy.io\n","\n","mat_data = scipy.io.loadmat('/content/preprocessed_Graz_2a/A09T_P.mat')\n","mat_data['data'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KcwMUuM5b7EE","executionInfo":{"status":"ok","timestamp":1686001871138,"user_tz":-60,"elapsed":26,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}},"outputId":"c55301a4-6333-4dbb-d3c9-1097fe00691f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(464, 22, 1000)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sn6-JUeCWcte"},"outputs":[],"source":["import argparse\n","import os\n","gpus = [0]\n","os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, gpus))\n","import numpy as np\n","import math\n","import glob\n","import random\n","import itertools\n","import datetime\n","import time\n","import datetime\n","import sys\n","import scipy.io\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image, make_grid\n","\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","from torchsummary import summary\n","import torch.autograd as autograd\n","from torchvision.models import vgg19\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import torch.nn.init as init\n","\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import torchvision.transforms as transforms\n","from sklearn.decomposition import PCA\n","\n","import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","from torch import nn\n","from torch import Tensor\n","from PIL import Image\n","from torchvision.transforms import Compose, Resize, ToTensor\n","from einops import rearrange, reduce, repeat\n","from einops.layers.torch import Rearrange, Reduce\n","# from common_spatial_pattern import csp\n","\n","import matplotlib.pyplot as plt\n","# from torch.utils.tensorboard import SummaryWriter\n","from torch.backends import cudnn\n","cudnn.benchmark = False\n","cudnn.deterministic = True\n"]},{"cell_type":"code","source":["# writer = SummaryWriter('./TensorBoardX/')\n","\n","\n","# Convolution module\n","# use conv to capture local features, instead of postion embedding.\n","class PatchEmbedding(nn.Module):\n","    def __init__(self, emb_size=40):\n","        # self.patch_size = patch_size\n","        super().__init__()\n","\n","        self.shallownet = nn.Sequential(\n","            nn.Conv2d(1, 40, (1, 25), (1, 1)),\n","            # original 2d setting\n","            # nn.Conv2d(40, 40, (22, 1), (1, 1)),\n","\n","            # same logic as above with 3d compressed data\n","            # nn.Conv2d(40, 40, (24, 1), (1, 1)),\n","\n","            # a setting considering the structure of the 3d compressed data\n","            nn.Conv2d(40, 40, (6, 1), (6, 1)),\n","            nn.Conv2d(40, 40, (4, 1), (1, 1)),\n","\n","            nn.BatchNorm2d(40),\n","            nn.ELU(),\n","            nn.AvgPool2d((1, 75), (1, 15)),  # pooling acts as slicing to obtain 'patch' along the time dimension as in ViT\n","            nn.Dropout(0.5),\n","        )\n","\n","        self.projection = nn.Sequential(\n","            nn.Conv2d(40, emb_size, (1, 1), stride=(1, 1)),  # transpose, conv could enhance fiting ability slightly\n","            Rearrange('b e (h) (w) -> b (h w) e'),\n","        )\n","\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        b, _, _, _ = x.shape\n","        x = self.shallownet(x)\n","        x = self.projection(x)\n","\n","        return x\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, emb_size, num_heads, dropout):\n","        super().__init__()\n","        self.emb_size = emb_size\n","        self.num_heads = num_heads\n","        self.keys = nn.Linear(emb_size, emb_size)\n","        self.queries = nn.Linear(emb_size, emb_size)\n","        self.values = nn.Linear(emb_size, emb_size)\n","        self.att_drop = nn.Dropout(dropout)\n","        self.projection = nn.Linear(emb_size, emb_size)\n","\n","    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n","        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n","        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n","        values = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n","        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)\n","        if mask is not None:\n","            fill_value = torch.finfo(torch.float32).min\n","            energy.mask_fill(~mask, fill_value)\n","\n","        scaling = self.emb_size ** (1 / 2)\n","        att = F.softmax(energy / scaling, dim=-1)\n","        att = self.att_drop(att)\n","        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n","        out = rearrange(out, \"b h n d -> b n (h d)\")\n","        out = self.projection(out)\n","        return out\n","\n","\n","class ResidualAdd(nn.Module):\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def forward(self, x, **kwargs):\n","        res = x\n","        x = self.fn(x, **kwargs)\n","        x += res\n","        return x\n","\n","\n","class FeedForwardBlock(nn.Sequential):\n","    def __init__(self, emb_size, expansion, drop_p):\n","        super().__init__(\n","            nn.Linear(emb_size, expansion * emb_size),\n","            nn.GELU(),\n","            nn.Dropout(drop_p),\n","            nn.Linear(expansion * emb_size, emb_size),\n","        )\n","\n","\n","class GELU(nn.Module):\n","    def forward(self, input: Tensor) -> Tensor:\n","        return input*0.5*(1.0+torch.erf(input/math.sqrt(2.0)))\n","\n","\n","class TransformerEncoderBlock(nn.Sequential):\n","    def __init__(self,\n","                 emb_size,\n","                 num_heads=10,\n","                 drop_p=0.5,\n","                 forward_expansion=4,\n","                 forward_drop_p=0.5):\n","        super().__init__(\n","            ResidualAdd(nn.Sequential(\n","                nn.LayerNorm(emb_size),\n","                MultiHeadAttention(emb_size, num_heads, drop_p),\n","                nn.Dropout(drop_p)\n","            )),\n","            ResidualAdd(nn.Sequential(\n","                nn.LayerNorm(emb_size),\n","                FeedForwardBlock(\n","                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n","                nn.Dropout(drop_p)\n","            )\n","            ))\n","\n","\n","class TransformerEncoder(nn.Sequential):\n","    def __init__(self, depth, emb_size):\n","        super().__init__(*[TransformerEncoderBlock(emb_size) for _ in range(depth)])\n","\n","\n","class ClassificationHead(nn.Sequential):\n","    def __init__(self, emb_size, n_classes):\n","        super().__init__()\n","\n","        # global average pooling\n","        self.clshead = nn.Sequential(\n","            Reduce('b n e -> b e', reduction='mean'),\n","            nn.LayerNorm(emb_size),\n","            nn.Linear(emb_size, n_classes)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(2440, 256),\n","            nn.ELU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, 32),\n","            nn.ELU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(32, 4)\n","        )\n","\n","    def forward(self, x):\n","        x = x.contiguous().view(x.size(0), -1)\n","        out = self.fc(x)\n","        return x, out\n","\n","\n","class Conformer(nn.Sequential):\n","    def __init__(self, emb_size=40, depth=6, n_classes=4, **kwargs):\n","        super().__init__(\n","\n","            PatchEmbedding(emb_size),\n","            TransformerEncoder(depth, emb_size),\n","            ClassificationHead(emb_size, n_classes)\n","        )\n","\n","\n","class ExP():\n","    def __init__(self, nsub):\n","        super(ExP, self).__init__()\n","        #self.batch_size = 72\n","        self.batch_size = 12\n","        self.n_epochs = 500\n","        self.c_dim = 4\n","        self.lr = 0.0001\n","        self.b1 = 0.5\n","        self.b2 = 0.999\n","        self.dimension = (190, 50)\n","        self.nSub = nsub\n","\n","        self.start_epoch = 0\n","        self.root = ''\n","\n","        self.log_write = open(\"log_subject%d.txt\" % self.nSub, \"w\")\n","\n","\n","        self.Tensor = torch.cuda.FloatTensor\n","        self.LongTensor = torch.cuda.LongTensor\n","\n","        self.criterion_l1 = torch.nn.L1Loss().cuda()\n","        self.criterion_l2 = torch.nn.MSELoss().cuda()\n","        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n","\n","        self.model = Conformer().cuda()\n","        self.model = nn.DataParallel(self.model, device_ids=[i for i in range(len(gpus))])\n","        self.model = self.model.cuda()\n","        # summary(self.model, (1, 22, 1000))\n","\n","\n","    # Segmentation and Reconstruction (S&R) data augmentation\n","    def interaug(self, timg, label):\n","        aug_data = []\n","        aug_label = []\n","        for cls4aug in range(4):\n","            cls_idx = np.where(label == cls4aug + 1)\n","            tmp_data = timg[cls_idx]\n","            tmp_data = np.expand_dims(tmp_data, axis=1)\n","            tmp_label = label[cls_idx]\n","\n","\n","            tmp_aug_data = np.zeros((int(self.batch_size / 4), 1, 24, 1000))\n","            for ri in range(int(self.batch_size / 4)):\n","                for rj in range(8):\n","                    rand_idx = np.random.randint(0, tmp_data.shape[0], 8)\n","                    tmp_aug_data[ri, :, :, rj * 125:(rj + 1) * 125] = tmp_data[rand_idx[rj], :, :, rj * 125:(rj + 1) * 125]\n","\n","            aug_data.append(tmp_aug_data)\n","            aug_label.append(tmp_label[:int(self.batch_size / 4)])\n","        aug_data = np.concatenate(aug_data)\n","        aug_label = np.concatenate(aug_label)\n","        aug_shuffle = np.random.permutation(len(aug_data))\n","        aug_data = aug_data[aug_shuffle, :, :]\n","        aug_label = aug_label[aug_shuffle]\n","\n","        aug_data = torch.from_numpy(aug_data).cuda()\n","        aug_data = aug_data.float()\n","        aug_label = torch.from_numpy(aug_label-1).cuda()\n","        aug_label = aug_label.long()\n","        return aug_data, aug_label\n","\n","    def get_source_data(self):\n","\n","        # train data\n","        #self.total_data = scipy.io.loadmat(self.root + 'A0%dT_P.mat' % self.nSub)\n","        #self.total_data = scipy.io.loadmat(self.root + 'merged_Graz_2d_T.mat')\n","        #self.total_data = scipy.io.loadmat( '/content/drive/MyDrive/3dCompressedGraz/trans_3Dnorm_2d_0%dT_P.mat' % self.nSub)\n","        self.total_data = scipy.io.loadmat('/content/drive/MyDrive/3dCompressedMergedGraz/merged_Graz_3dcompressed_T.mat')\n","\n","        self.train_data = self.total_data['data']\n","        self.train_label = self.total_data['label']\n","\n","        # self.train_data = np.transpose(self.train_data, (2, 1, 0))\n","        self.train_data = np.expand_dims(self.train_data, axis=1)\n","        self.train_label = np.transpose(self.train_label)\n","\n","        self.allData = self.train_data\n","        self.allLabel = self.train_label\n","\n","        shuffle_num = np.random.permutation(len(self.allData))\n","        self.allData = self.allData[shuffle_num, :, :, :]\n","        self.allLabel = self.allLabel[shuffle_num]\n","\n","        # test data\n","        #self.test_tmp = scipy.io.loadmat(self.root + 'A0%dE_P.mat' % self.nSub)\n","        #self.test_tmp = scipy.io.loadmat(self.root + 'merged_Graz_2d_E.mat')\n","        #self.test_tmp = scipy.io.loadmat( '/content/drive/MyDrive/3dCompressedGraz/trans_3Dnorm_2d_0%dE_P.mat' % self.nSub)\n","        self.test_tmp = scipy.io.loadmat('/content/drive/MyDrive/3dCompressedMergedGraz/merged_Graz_3dcompressed_E.mat')\n","        self.test_data = self.test_tmp['data']\n","        self.test_label = self.test_tmp['label']\n","\n","        # self.test_data = np.transpose(self.test_data, (2, 1, 0))\n","        self.test_data = np.expand_dims(self.test_data, axis=1)\n","        self.test_label = np.transpose(self.test_label)\n","\n","        self.testData = self.test_data\n","        self.testLabel = np.squeeze(self.test_label)\n","\n","        #print(self.allData)\n","        # standardize\n","        target_mean = np.mean(self.allData, axis=0)\n","        target_std = np.std(self.allData)\n","\n","        self.allData = (self.allData - target_mean) / target_std\n","        self.testData = (self.testData - target_mean) / target_std\n","\n","        # data shape: (trial, conv channel, electrode channel, time samples)\n","        return self.allData, self.allLabel, self.testData, self.testLabel\n","\n","\n","    def train(self):\n","\n","        img, label, test_data, test_label = self.get_source_data()\n","        img = torch.from_numpy(img)\n","        label = torch.from_numpy(label - 1)\n","\n","        dataset = torch.utils.data.TensorDataset(img, label)\n","        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n","\n","        test_data = torch.from_numpy(test_data)\n","        test_label = torch.from_numpy(test_label - 1)\n","        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n","        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n","\n","        # Optimizers\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n","\n","        test_data = Variable(test_data.type(self.Tensor))\n","        test_label = Variable(test_label.type(self.LongTensor))\n","\n","        bestAcc = 0\n","        averAcc = 0\n","        num = 0\n","        Y_true = 0\n","        Y_pred = 0\n","\n","        # Train the cnn model\n","        total_step = len(self.dataloader)\n","        curr_lr = self.lr\n","\n","        for e in range(self.n_epochs):\n","            # in_epoch = time.time()\n","            self.model.train()\n","            for i, (img, label) in enumerate(self.dataloader):\n","\n","                img = Variable(img.cuda().type(self.Tensor))\n","                label = Variable(label.cuda().type(self.LongTensor))\n","\n","                # data augmentation\n","                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n","                img = torch.cat((img, aug_data))\n","\n","                label = torch.squeeze(label, dim=1)\n","                label = torch.cat((label, aug_label))\n","\n","\n","                tok, outputs = self.model(img)\n","\n","\n","                loss = self.criterion_cls(outputs, label)\n","\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","\n","\n","            # out_epoch = time.time()\n","\n","\n","            # test process\n","            if (e + 1) % 1 == 0:\n","                self.model.eval()\n","                Tok, Cls = self.model(test_data)\n","\n","                loss_test = self.criterion_cls(Cls, test_label)\n","                y_pred = torch.max(Cls, 1)[1]\n","                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n","                train_pred = torch.max(outputs, 1)[1]\n","                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n","\n","                print('Epoch:', e,\n","                      '  Train loss: %.6f' % loss.detach().cpu().numpy(),\n","                      '  Test loss: %.6f' % loss_test.detach().cpu().numpy(),\n","                      '  Train accuracy %.6f' % train_acc,\n","                      '  Test accuracy is %.6f' % acc)\n","\n","                self.log_write.write(str(e) + \"    \" +str(loss.detach().cpu().numpy())+\"    \"+\n","                                     str(loss_test.detach().cpu().numpy())+\"    \"+str(train_acc) +\"     \"+ str(acc)+ \"\\n\")\n","                num = num + 1\n","                averAcc = averAcc + acc\n","                if acc > bestAcc:\n","                    bestAcc = acc\n","                    Y_true = test_label\n","                    Y_pred = y_pred\n","\n","\n","        torch.save(self.model.module.state_dict(), 'model.pth')\n","        averAcc = averAcc / num\n","        print('The average accuracy is:', averAcc)\n","        print('The best accuracy is:', bestAcc)\n","        self.log_write.write('The average accuracy is: ' + str(averAcc) + \"\\n\")\n","        self.log_write.write('The best accuracy is: ' + str(bestAcc) + \"\\n\")\n","\n","        return bestAcc, averAcc, Y_true, Y_pred\n","        # writer.close()\n","\n","\n","def main():\n","    best = 0\n","    aver = 0\n","    result_write = open(\"sub_result.txt\", \"w\")\n","\n","    for i in range(1):\n","        starttime = datetime.datetime.now()\n","\n","\n","        seed_n = np.random.randint(2021)\n","        print('seed is ' + str(seed_n))\n","        random.seed(seed_n)\n","        np.random.seed(seed_n)\n","        torch.manual_seed(seed_n)\n","        torch.cuda.manual_seed(seed_n)\n","        torch.cuda.manual_seed_all(seed_n)\n","\n","\n","        print('Subject %d' % (i+1))\n","        exp = ExP(i + 1)\n","\n","        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n","        print('THE BEST ACCURACY IS ' + str(bestAcc))\n","        result_write.write('Subject ' + str(i + 1) + ' : ' + 'Seed is: ' + str(seed_n) + \"\\n\")\n","        result_write.write('Subject ' + str(i + 1) + ' : ' + 'The best accuracy is: ' + str(bestAcc) + \"\\n\")\n","        result_write.write('Subject ' + str(i + 1) + ' : ' + 'The average accuracy is: ' + str(averAcc) + \"\\n\")\n","\n","        endtime = datetime.datetime.now()\n","        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n","        best = best + bestAcc\n","        aver = aver + averAcc\n","        if i == 0:\n","            yt = Y_true\n","            yp = Y_pred\n","        else:\n","            yt = torch.cat((yt, Y_true))\n","            yp = torch.cat((yp, Y_pred))\n","\n","\n","    best = best / 9\n","    aver = aver / 9\n","\n","    result_write.write('**The average Best accuracy is: ' + str(best) + \"\\n\")\n","    result_write.write('The average Aver accuracy is: ' + str(aver) + \"\\n\")\n","    result_write.close()\n","\n","\n","if __name__ == \"__main__\":\n","    print(time.asctime(time.localtime(time.time())))\n","    main()\n","    print(time.asctime(time.localtime(time.time())))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"x-91HBp7Xexd","outputId":"19568592-af0c-4040-96d8-a201a3af3e78","executionInfo":{"status":"error","timestamp":1686477152530,"user_tz":-60,"elapsed":668,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jun 11 09:52:31 2023\n","seed is 921\n","Subject 1\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-f43b2c88dd7f>\u001b[0m in \u001b[0;36m<cell line: 418>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-f43b2c88dd7f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Subject %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mbestAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-f43b2c88dd7f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nsub)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}]},{"cell_type":"code","source":["import glob\n","import shutil\n","\n","# Get a list of .mat files matching the pattern\n","file_list = glob.glob('*.txt')\n","\n","# Specify the destination directory in Google Drive\n","destination_directory = '/content/drive/MyDrive/ResultMergedGraz3dApproach1.2/'\n","\n","# Iterate over each .mat file\n","for file_path in file_list:\n","    # Copy the file to the destination directory\n","    shutil.copy(file_path, destination_directory)"],"metadata":{"id":"QVjL1ad2K-2j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"kfiDFUJ9LxFo"}}]}