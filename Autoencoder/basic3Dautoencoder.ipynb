{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOUO57q150wIHrbwqN/1urg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqW5xfrDcGnI","executionInfo":{"status":"ok","timestamp":1686391878045,"user_tz":-60,"elapsed":15211,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}},"outputId":"daeb0dd4-c2a6-4e86-cabb-28bc46455401"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import scipy.io\n","import glob\n","import torch\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import scipy.io as sio\n","from torchvision import datasets, transforms\n","\n","\n","class CustomActivation(nn.Module):\n","    def forward(self, x):\n","        # Apply your custom activation function\n","        # Replace this line with your desired custom activation function\n","        return 8 * torch.tanh(x)\n","\n","class Autoencoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Encoder layers\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1, 1, kernel_size=(3, 2), stride=1, padding=0),\n","            nn.ReLU(),\n","        )\n","\n","        # Decoder layers\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(1, 1, kernel_size=(3, 2), stride=1, padding=0),\n","            CustomActivation(),  # Use the custom activation function\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","\n","    def encode(self, x):\n","        x = self.encoder(x)\n","        return x\n","\n","def train(model, num_epochs=5, batch_size=64, learning_rate=1e-3):\n","    torch.manual_seed(42)\n","    criterion = nn.MSELoss()  # Mean Square Error loss\n","    optimizer = torch.optim.Adam(model.parameters(),\n","                                 lr=learning_rate,\n","                                 weight_decay=1e-5)\n","\n","    training_data = dataset\n","    best_loss = float('inf')  # Initialize with a high value\n","\n","    for epoch in range(num_epochs):\n","        for data in training_data:\n","            img = data\n","            recon = model(img)\n","            loss = criterion(recon, img)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        # Save the model if the current loss is the best so far\n","        if loss < best_loss:\n","            best_loss = loss\n","            torch.save(model.state_dict(), 'best_model.pth')\n","\n","        print('Epoch:{}, Loss:{:.4f}'.format(epoch + 1, float(loss)))\n","\n","    print('Training complete.')"],"metadata":{"id":"LZDaIN_OeVT9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(1,10):\n","    # train autoencoder\n","    raw_data = scipy.io.loadmat(f'/content/drive/MyDrive/3dGrazNormalized/3Dnorm_2d_{i:02d}T_P.mat')['data']\n","    data = torch.empty(len(raw_data)*1000, 6, 7)\n","\n","    counter = 0\n","    for d in raw_data:\n","        d = torch.tensor(np.array(d))\n","        for dd in torch.split(d, 1, dim=2):\n","            data[counter] = torch.squeeze(dd)\n","            counter += 1\n","    data = data.unsqueeze(1)\n","    print(data.shape)\n","    dataset = data.float()\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(str(device))\n","    model = Autoencoder().to(device)\n","    dataset = dataset.to(device)\n","    max_epochs = 3\n","    train(model, num_epochs=max_epochs)\n","\n","\n","    # load best model and transform data\n","    model.load_state_dict(torch.load('best_model.pth'))\n","    file_list = glob.glob(f'/content/drive/MyDrive/3dGrazNormalized/3Dnorm_2d_{i:02d}*.mat')\n","    for f in file_list:\n","\n","        trans = []\n","\n","        for d in scipy.io.loadmat(f)['data']:\n","            d = torch.tensor(np.array(d))\n","            d = torch.split(d, 1, dim=2)\n","            trans_d = []\n","\n","            for dd in d:\n","                dd = torch.squeeze(dd).float().unsqueeze(0).to(device)\n","                compressed_dd = torch.squeeze(model.encode(dd).cpu().detach())\n","                trans_d.append(np.array(compressed_dd).flatten())\n","\n","            trans_d = np.transpose(np.array(trans_d), (1, 0))\n","\n","\n","            trans.append(trans_d)\n","\n","        subject_data = {'data': trans, 'label': scipy.io.loadmat(f)['label']}\n","        sio.savemat('trans_'+ f.split('/')[-1], subject_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQNZ-mZzS4qC","outputId":"30e6227d-766f-4128-d939-71839f2b2e48","executionInfo":{"status":"ok","timestamp":1686401103191,"user_tz":-60,"elapsed":9219913,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([463000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0306\n","Epoch:2, Loss:0.0306\n","Epoch:3, Loss:0.0306\n","Training complete.\n","torch.Size([464000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0792\n","Epoch:2, Loss:0.0792\n","Epoch:3, Loss:0.0792\n","Training complete.\n","torch.Size([464000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0517\n","Epoch:2, Loss:0.0517\n","Epoch:3, Loss:0.0517\n","Training complete.\n","torch.Size([464000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0863\n","Epoch:2, Loss:0.0863\n","Epoch:3, Loss:0.0863\n","Training complete.\n","torch.Size([464000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0448\n","Epoch:2, Loss:0.0448\n","Epoch:3, Loss:0.0448\n","Training complete.\n","torch.Size([464000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0186\n","Epoch:2, Loss:0.0186\n","Epoch:3, Loss:0.0186\n","Training complete.\n","torch.Size([464000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0441\n","Epoch:2, Loss:0.0441\n","Epoch:3, Loss:0.0441\n","Training complete.\n","torch.Size([464000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0613\n","Epoch:2, Loss:0.0613\n","Epoch:3, Loss:0.0613\n","Training complete.\n","torch.Size([464000, 1, 6, 7])\n","cpu\n","Epoch:1, Loss:0.0840\n","Epoch:2, Loss:0.0840\n","Epoch:3, Loss:0.0840\n","Training complete.\n"]}]},{"cell_type":"code","source":["import glob\n","import shutil\n","\n","# Get a list of .mat files matching the pattern\n","file_list = glob.glob('trans*.mat')\n","\n","# Specify the destination directory in Google Drive\n","destination_directory = '/content/drive/MyDrive/3dCompressedGraz/'\n","\n","# Iterate over each .mat file\n","for file_path in file_list:\n","    # Copy the file to the destination directory\n","    shutil.copy(file_path, destination_directory)"],"metadata":{"id":"-pcf41pmEEAp"},"execution_count":null,"outputs":[]}]}