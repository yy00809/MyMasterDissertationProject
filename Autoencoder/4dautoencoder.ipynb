{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1779,"status":"ok","timestamp":1687384833142,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"},"user_tz":-60},"id":"S1OKyKmud2vS","outputId":"58effbb4-b1f4-4005-e7b3-3d9460ea5899"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"jlm-s6m2-S5V"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4744,"status":"ok","timestamp":1687384837885,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"},"user_tz":-60},"id":"Y2widTHomvP6","outputId":"de0093b8-db2b-4481-d729-94e51ad92284"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([1, 1000, 6, 7, 4])\n","Output shape: torch.Size([1, 1000, 4, 5, 1])\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","# Create a random input tensor\n","input_tensor = torch.randn(1, 1000, 6, 7, 4)  # (batch_size, in_channels, depth, height, width)\n","\n","# Instantiate the nn.Conv3d layer\n","conv_layer = nn.Conv3d(in_channels=1000, out_channels=1000, kernel_size=(1,1,6), stride=2, padding=1)\n","\n","# Pass the input tensor through the conv_layer\n","output_tensor = conv_layer(input_tensor)\n","\n","# Print the shapes of the input and output tensors\n","print(\"Input shape:\", input_tensor.shape)\n","print(\"Output shape:\", output_tensor.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":358,"status":"ok","timestamp":1687384838228,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"},"user_tz":-60},"id":"7UHLq5uCnFIg","outputId":"1e19f408-843c-42c9-8357-993e6f597c06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([1, 1000, 6, 7, 4])\n","Output shape: torch.Size([1, 1000, 1, 7, 1])\n"]}],"source":["input_tensor = torch.randn(1, 1000, 6, 7, 4)  # (batch_size, in_channels, depth, height, width)\n","\n","# Instantiate the nn.Conv3d layer\n","conv_layer = nn.Conv3d(in_channels=1000, out_channels=1000, kernel_size=(6,1,4), stride=1, padding=0)\n","# Pass the input tensor through the conv_layer\n","output_tensor = conv_layer(input_tensor)\n","\n","# Print the shapes of the input and output tensors\n","print(\"Input shape:\", input_tensor.shape)\n","print(\"Output shape:\", output_tensor.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1687384838478,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"},"user_tz":-60},"id":"VFanjRaznThj","outputId":"a9467e6b-34e6-46d6-d51b-7a992ab3a189"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([1, 1000, 1, 7, 1])\n","Output shape: torch.Size([1, 1000, 6, 7, 4])\n"]}],"source":["input_tensor = torch.randn(1, 1000, 1, 7, 1)  # (batch_size, in_channels, depth, height, width)\n","\n","# Instantiate the nn.Conv3d layer\n","conv_layer = nn.ConvTranspose3d(in_channels=1000, out_channels=1000, kernel_size=(6, 1, 4), stride=1, padding=0)\n","# Pass the input tensor through the conv_layer\n","output_tensor = conv_layer(input_tensor)\n","\n","# Print the shapes of the input and output tensors\n","print(\"Input shape:\", input_tensor.shape)\n","print(\"Output shape:\", output_tensor.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4WyqKWHghYU"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class CustomActivation(nn.Module):\n","    def __init__(self, scaling_factor=8):\n","        super(CustomActivation, self).__init__()\n","        self.scaling_factor = scaling_factor\n","\n","    def forward(self, x):\n","        # Apply your custom activation function\n","        return self.scaling_factor * torch.tanh(x)\n","\n","# Define the encoder architecture\n","class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        self.conv1 = nn.Conv3d(in_channels=1000, out_channels=1500, kernel_size=(1, 1, 4), stride=1, padding=0)\n","        self.conv2 = nn.Conv3d(in_channels=1500, out_channels=1000, kernel_size=(6, 1, 1), stride=1, padding=0)\n","\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = torch.relu(self.conv2(x))\n","\n","        return x\n","\n","# Define the decoder architecture\n","class Decoder(nn.Module):\n","    def __init__(self, scaling_factor=8):\n","        super(Decoder, self).__init__()\n","        self.conv1 = nn.ConvTranspose3d(in_channels=1000, out_channels=1500, kernel_size=(6, 1, 1), stride=1, padding=0)\n","        self.conv2 = nn.ConvTranspose3d(in_channels=1500, out_channels=1000, kernel_size=(1, 1, 4), stride=1, padding=0)\n","        self.activation = CustomActivation(scaling_factor)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.activation(x)\n","        return x\n","\n","# Combine the encoder and decoder into a single autoencoder model\n","class Autoencoder(nn.Module):\n","    def __init__(self, scaling_factor=8):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder(scaling_factor)\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return encoded, decoded\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWVBJaD8giDh","outputId":"db09f947-3dbc-4e70-f500-67eb330f139e","executionInfo":{"status":"ok","timestamp":1687385415959,"user_tz":-60,"elapsed":577483,"user":{"displayName":"小格的厨房","userId":"15544253962028588444"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Loss: 0.1313\n","Epoch [2/5], Loss: 0.1313\n","Epoch [3/5], Loss: 0.1312\n","Epoch [4/5], Loss: 0.1312\n","Epoch [5/5], Loss: 0.1312\n","Epoch [1/5], Loss: 6.8753\n","Epoch [2/5], Loss: 0.1390\n","Epoch [3/5], Loss: 0.1314\n","Epoch [4/5], Loss: 0.1314\n","Epoch [5/5], Loss: 0.1316\n","Epoch [1/5], Loss: 2.2302\n","Epoch [2/5], Loss: 0.1432\n","Epoch [3/5], Loss: 0.1313\n","Epoch [4/5], Loss: 0.1313\n","Epoch [5/5], Loss: 0.1313\n","Epoch [1/5], Loss: 0.3300\n","Epoch [2/5], Loss: 0.1320\n","Epoch [3/5], Loss: 0.1318\n","Epoch [4/5], Loss: 0.1318\n","Epoch [5/5], Loss: 0.1317\n","Epoch [1/5], Loss: 0.1312\n","Epoch [2/5], Loss: 0.1311\n","Epoch [3/5], Loss: 0.1311\n","Epoch [4/5], Loss: 0.1311\n","Epoch [5/5], Loss: 38.7918\n","Epoch [1/5], Loss: 0.1314\n","Epoch [2/5], Loss: 37.4166\n","Epoch [3/5], Loss: 103.8283\n","Epoch [4/5], Loss: 102.5299\n","Epoch [5/5], Loss: 75.5680\n","Epoch [1/5], Loss: 0.1312\n","Epoch [2/5], Loss: 0.1311\n","Epoch [3/5], Loss: 0.1311\n","Epoch [4/5], Loss: 0.1311\n","Epoch [5/5], Loss: 0.1311\n","Epoch [1/5], Loss: 0.1816\n","Epoch [2/5], Loss: 5.9282\n","Epoch [3/5], Loss: 0.1435\n","Epoch [4/5], Loss: 0.1315\n","Epoch [5/5], Loss: 0.1315\n","Epoch [1/5], Loss: 0.1314\n","Epoch [2/5], Loss: 0.1313\n","Epoch [3/5], Loss: 1.8187\n","Epoch [4/5], Loss: 67.8259\n","Epoch [5/5], Loss: 67.8111\n"]}],"source":["import torch.optim as optim\n","import numpy as np\n","fileindex = [2,3,8]\n","for i in range(1,10):\n","    # Prepare training data\n","    train_data = scipy.io.loadmat(f'/content/drive/MyDrive/4DGraz/4D_{i:02d}T_P.mat')['data']\n","    valid_data = scipy.io.loadmat(f'/content/drive/MyDrive/4DGraz/4D_{i:02d}E_P.mat')['data']\n","\n","\n","    max = np.max(train_data)\n","    min = np.min(train_data)\n","    model = None\n","    if max > min*(-1):\n","        model = Autoencoder(scaling_factor=max).to('cuda')\n","    else:\n","        model = Autoencoder(scaling_factor=min).to('cuda')\n","    # Define the autoencoder model\n","\n","\n","    # Define the loss function\n","    criterion = nn.MSELoss()\n","\n","    # Define the optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n","\n","    # Set the number of training epochs\n","    num_epochs = 5\n","\n","    # Initialize variables for tracking the best model\n","    best_loss = float('inf')\n","    best_model_path = 'best_model.pth'\n","\n","    # Training loop\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","\n","        # Iterate over the training data\n","        for inputs in train_data:\n","            # Zero the gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            inputs = torch.from_numpy(inputs).float()\n","            inputs = inputs.unsqueeze(0).permute(0, 4, 1, 2, 3).to('cuda')\n","            encoded, decoded = model(inputs)\n","\n","            # Calculate the loss\n","            loss = criterion(decoded, inputs)\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Update the parameters\n","            optimizer.step()\n","\n","            # Track the running loss\n","            running_loss += loss.item()\n","\n","        # Compute the average loss for the epoch\n","        epoch_loss = running_loss / len(train_data)\n","\n","        # Print the epoch loss\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n","\n","        # Validate the model\n","        valid_loss = 0.0\n","        for inputs in valid_data:\n","            with torch.no_grad():\n","                inputs = torch.from_numpy(inputs).float()\n","                inputs = inputs.unsqueeze(0).permute(0, 4, 1, 2, 3).to('cuda')\n","                encoded, decoded = model(inputs)\n","                loss = criterion(decoded, inputs)\n","                valid_loss += loss.item()\n","        valid_loss /= len(valid_data)\n","\n","        # Check if the current model is the best\n","        if valid_loss < best_loss:\n","            best_loss = valid_loss\n","            # Save the model checkpoint\n","            torch.save(model.state_dict(), best_model_path)\n","\n","    model.load_state_dict(torch.load('best_model.pth'))\n","    model.eval()\n","\n","    train = []\n","    for inputs in train_data:\n","        inputs = torch.from_numpy(inputs).float()\n","        inputs = inputs.unsqueeze(0).permute(0, 4, 1, 2, 3).to('cuda')\n","        encoded, _ = model(inputs)\n","        train.append(encoded.view(7, 1000).cpu().detach().numpy())\n","\n","    valid = []\n","    for inputs in valid_data:\n","        inputs = torch.from_numpy(inputs).float()\n","        inputs = inputs.unsqueeze(0).permute(0, 4, 1, 2, 3).to('cuda')\n","        encoded, _ = model(inputs)\n","        valid.append(encoded.view(7, 1000).cpu().detach().numpy())\n","\n","    train_data = {'data': np.array(train), 'label': scipy.io.loadmat(f'/content/drive/MyDrive/4DGraz/4D_{i:02d}T_P.mat')['label']}\n","    scipy.io.savemat(f'compressed4D_{i:02d}T_P.mat', train_data)\n","\n","    valid_data = {'data': np.array(valid), 'label': scipy.io.loadmat(f'/content/drive/MyDrive/4DGraz/4D_{i:02d}E_P.mat')['label']}\n","    scipy.io.savemat(f'compressed4D_{i:02d}E_P.mat', valid_data)\n"]},{"cell_type":"code","source":["import glob\n","import shutil\n","\n","# Get a list of .mat files matching the pattern\n","file_list = glob.glob('*.mat')\n","\n","# Specify the destination directory in Google Drive\n","destination_directory = '/content/drive/MyDrive/4DCompressedGraz/'\n","\n","# Iterate over each .mat file\n","for file_path in file_list:\n","    # Copy the file to the destination directory\n","    shutil.copy(file_path, destination_directory)"],"metadata":{"id":"RMqgh7_mydE2"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOrrLX4DPIX2wOlP7wzKh2d"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}